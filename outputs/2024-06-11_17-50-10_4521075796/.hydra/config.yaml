alg: lora
seed: 0
debug: false
model_save_pt: 5000
edit_bs: 1
silent: false
max_iters: 200100
log_interval: 100
val_interval: 5000
batch_size: 4
val_batch_size: 4
accumulate_bs: 10
cedit: 0.2
cloc: 1.0
cbase: 1.0
val_steps: 500
device: cuda
base_loss: distill
oracle: false
train: true
train_base: false
opt: Adam
single_batch: false
archive: null
grad_clip: 100.0
ref: null
early_stop_patience: 40000
early_stop_key: mixture/acc_val
dropout: 0.0
tokenizer: null
results_dir: null
no_grad_layers: null
eval_only: false
half: false
save: false
log_errors: false
unlikelihood: true
check_dir: null
batch_round: 10
re_init_model: false
max_n_edits: 10000
eval_data_dir: ${hydra:runtime.cwd}/data/
eval_result_dir: ${hydra:runtime.cwd}/results/MELO/
model:
  pt: ${hydra:runtime.cwd}/../hf_models/gpt2-xl
  name: gpt2-xl
  class_name: GPT2LMHeadModel
  tokenizer_class: GPT2TokenizerFast
  tokenizer_name: ${hydra:runtime.cwd}/../hf_models/gpt2-xl
  fan_in_fan_out: true
  target_modules:
  - transformer.h.36.mlp.c_fc
  - transformer.h.37.mlp.c_fc
  grace_layer: transformer.h.35.mlp.c_fc
data:
  path: null
  rephrase: true
  zsre_nq: false
  zsre_impl: false
  zsre_impl_path: ${hydra:runtime.cwd}/data/zsre/impl_{}.json
  zsre_yn: false
  zsre_yn_path: ${hydra:runtime.cwd}/data/zsre/zsre_yn_{}.txt
  zsre_eval_idxs: null
  zsre_path: ${hydra:runtime.cwd}/data/zsre/structured_zeroshot-{}-new_annotated_final.jsonl
  nq_path: ${hydra:runtime.cwd}/data/nq
  wiki_webtext: true
  n_edits: 1
  hard_neg: false
  hard_neg_neighbors: 100
  hard_neg_exclude: 25
  hard_neg_temp: 0.1
  hard_neg_prob: 0.5
  flip_inner_outer: false
  sent_eval_sample: false
  n_outer_max: null
eval:
  verbose: true
  log_interval: 100
  final_eval: true
lr: 0.0001
lr_lr: 0.0001
lora:
  cls_name: distilbert-base-cased
  cls_class: AutoModel
  supervised: true
  cos: false
  freeze: null
  square: true
  bound_embeds: false
  use_all_negatives: false
  freeze_lora: false
  dist_heads: 1
  cross_attend: false
  soft_weighting: false
  checkpoint_grad: false
  lora_r: 64
  lora_alpha: 64
  lora_dropout: 0.0
task: zsre
lora_task_type: CAUSAL_LM
grace:
  _name: grace
  num_iter: 50
  init_radius: 750
  dist_fn: euc
  val_init: cold
  val_train: sgd
  val_reg: None
  reg: early_stop
  replacement: replace_prompt
  expand_mode: moving_avg
  num_pert: 8
  key_id: -1
  num_edit_per_block: 100
  num_block: 100
  num_rank_per_block: 2
  metric_period: 200
  edit_lr: 0.002
