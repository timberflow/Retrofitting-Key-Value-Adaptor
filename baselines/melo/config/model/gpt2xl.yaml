name: gpt2-xl
class_name: GPT2LMHeadModel
tokenizer_class: GPT2TokenizerFast
tokenizer_name: ${hydra:runtime.cwd}/hf_models/gpt2-xl

fan_in_fan_out: True
target_modules:
  - transformer.h.36.mlp.c_fc
  - transformer.h.37.mlp.c_fc


#pt: null
pt: ${hydra:runtime.cwd}/hf_models/gpt2-xl # set this to 'hallucination' inside your checkpoint directory
#model.base_model.h[35]



grace_layer: transformer.h.35.mlp.c_fc